{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2c2b4a0-f795-4c95-89f2-e99a14262ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Starting the Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MovieLens-1M\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Loading the my dataset\n",
    "df = spark.read.csv(\"/home/jovyan/data/1MMovieDataset.csv\", header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56ab862e-3dbe-4935-a18d-78ee231c411f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- vote_average: string (nullable = true)\n",
      " |-- vote_count: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- release_date: string (nullable = true)\n",
      " |-- revenue: string (nullable = true)\n",
      " |-- runtime: string (nullable = true)\n",
      " |-- budget: string (nullable = true)\n",
      " |-- original_language: string (nullable = true)\n",
      " |-- popularity: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      " |-- imdb_rating: string (nullable = true)\n",
      " |-- imdb_votes: string (nullable = true)\n",
      "\n",
      "+---+--------------------+------------+----------+--------+------------+--------+-------+--------+-----------------+----------+--------------------+-----------+----------+\n",
      "| id|               title|vote_average|vote_count|  status|release_date| revenue|runtime|  budget|original_language|popularity|              genres|imdb_rating|imdb_votes|\n",
      "+---+--------------------+------------+----------+--------+------------+--------+-------+--------+-----------------+----------+--------------------+-----------+----------+\n",
      "|  2|               Ariel|         7.1|       346|Released|  21/10/1988|       0|     73|       0|               fi|    1.7519|Comedy, Drama, Ro...|        7.4|      9229|\n",
      "|  3| Shadows in Paradise|       7.293|       409|Released|  17/10/1986|       0|     74|       0|               fi|    1.9295|Comedy, Drama, Ro...|        7.4|      8062|\n",
      "|  5|          Four Rooms|         5.9|      2698|Released|  09/12/1995| 4257354|     98| 4000000|               en|    2.7943|              Comedy|        6.7|    114428|\n",
      "|  6|      Judgment Night|         6.5|       351|Released|  15/10/1993|12136938|    109|21000000|               en|    1.8302|Action, Crime, Th...|        6.6|     20049|\n",
      "|  8|Life in Loops (A ...|         7.5|        27|Released|  01/01/2006|       0|     80|   42000|               en|     3.203|         Documentary|        8.1|       285|\n",
      "+---+--------------------+------------+----------+--------+------------+--------+-------+--------+-----------------+----------+--------------------+-----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the structure of the DataFrame, including column names and data types\n",
    "df.printSchema()\n",
    "\n",
    "# Show the first 5 rows of the dataset\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cec9e11a-fe6f-4965-9241-d7d4e56c7339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------------+----------+------+------------+-------+-------+------+-----------------+----------+------+-----------+----------+\n",
      "| id|title|vote_average|vote_count|status|release_date|revenue|runtime|budget|original_language|popularity|genres|imdb_rating|imdb_votes|\n",
      "+---+-----+------------+----------+------+------------+-------+-------+------+-----------------+----------+------+-----------+----------+\n",
      "|  0|   14|           1|         1|     1|      111800|     10|      2|     1|                1|         1|292560|     604301|    604343|\n",
      "+---+-----+------------+----------+------+------------+-------+-------+------+-----------------+----------+------+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, isnan, when, count\n",
    "\n",
    "# In each column, count \"null\" or \"NaN\" values \n",
    "df.select([count(when(col(c).isNull() | isnan(c), c)).alias(c) for c in df.columns]).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6efafea4-810b-4841-829a-82e0ccb4bf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns, cause high missing values and will not be used in analysis\n",
    "df = df.drop(\"imdb_rating\", \"imdb_votes\", \"genres\", \"release_date\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f09fc966-c1f1-451b-bfec-d89134ed0ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- vote_average: string (nullable = true)\n",
      " |-- vote_count: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- revenue: string (nullable = true)\n",
      " |-- runtime: string (nullable = true)\n",
      " |-- budget: string (nullable = true)\n",
      " |-- original_language: string (nullable = true)\n",
      " |-- popularity: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema() # showing the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69ddaad1-1506-4127-87bc-5c0e8e7c1c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------------+----------+------+-------+-------+------+-----------------+----------+\n",
      "| id|title|vote_average|vote_count|status|revenue|runtime|budget|original_language|popularity|\n",
      "+---+-----+------------+----------+------+-------+-------+------+-----------------+----------+\n",
      "|  0|   14|           1|         1|     1|     10|      2|     1|                1|         1|\n",
      "+---+-----+------------+----------+------+-------+-------+------+-----------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In each column, count \"null\" or \"NaN\" values \n",
    "df.select([count(when(col(c).isNull() | isnan(c), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1a8dbe0-adea-4ce1-9c95-7155e8d9e5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------+\n",
      "|original_language|language_index|\n",
      "+-----------------+--------------+\n",
      "|               fi|          29.0|\n",
      "|               fi|          29.0|\n",
      "|               en|           0.0|\n",
      "|               en|           0.0|\n",
      "|               en|           0.0|\n",
      "+-----------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# StringIndexer to convert language to \"numerical index\"\n",
    "indexer = StringIndexer(inputCol=\"original_language\", outputCol=\"language_index\")\n",
    "df = indexer.fit(df).transform(df)\n",
    "\n",
    "# Showing the new column\n",
    "df.select(\"original_language\", \"language_index\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e6ee5b2-ccd1-42f7-9f27-f5492b4e53b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+\n",
      "|vote_average|rating_level|\n",
      "+------------+------------+\n",
      "|         7.1|        good|\n",
      "|       7.293|        good|\n",
      "|         5.9|     average|\n",
      "|         6.5|        good|\n",
      "|         7.5|        good|\n",
      "|         6.8|        good|\n",
      "|         8.2|   excellent|\n",
      "|       7.816|        good|\n",
      "|       8.468|   excellent|\n",
      "|       8.006|   excellent|\n",
      "+------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "# Add a new column called rating_level based on vote_average\n",
    "df = df.withColumn(\"rating_level\",\n",
    "    when(df[\"vote_average\"] >= 8, \"excellent\")\n",
    "    .when(df[\"vote_average\"] >= 6, \"good\")\n",
    "    .when(df[\"vote_average\"] >= 4, \"average\")\n",
    "    .otherwise(\"poor\")\n",
    ")\n",
    "\n",
    "# Preview\n",
    "df.select(\"vote_average\", \"rating_level\").show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acafd21a-0c0b-4c72-b447-e5e45422220f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- vote_average: string (nullable = true)\n",
      " |-- vote_count: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- revenue: string (nullable = true)\n",
      " |-- runtime: string (nullable = true)\n",
      " |-- budget: string (nullable = true)\n",
      " |-- original_language: string (nullable = true)\n",
      " |-- popularity: string (nullable = true)\n",
      " |-- language_index: double (nullable = false)\n",
      " |-- rating_level: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema() # showing the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b076e965-840b-4cfe-9181-e391b56df5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- vote_average: string (nullable = true)\n",
      " |-- vote_count: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- revenue: string (nullable = true)\n",
      " |-- runtime: string (nullable = true)\n",
      " |-- budget: string (nullable = true)\n",
      " |-- original_language: string (nullable = true)\n",
      " |-- popularity: string (nullable = true)\n",
      " |-- language_index: double (nullable = false)\n",
      " |-- rating_level: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop unnecessary columns again due to kernel reset\n",
    "columns_to_drop = [\"genres\", \"imdb_rating\", \"imdb_votes\"]\n",
    "\n",
    "# Create cleaned DataFrame\n",
    "df_cleaned = df.drop(*columns_to_drop)\n",
    "\n",
    "# Confirm structure is ready for HiveQL\n",
    "df_cleaned.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1900befa-4131-44a7-b5aa-db31812405b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the cleaned DataFrame as a temporary SQL view called \"movies\"\n",
    "df_cleaned.createOrReplaceTempView(\"movies\")\n",
    "# This allows us to run SQL queries as if it were a Hive table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45fd4d28-efe8-40dc-82bb-c59383835506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------+\n",
      "|original_language| count|\n",
      "+-----------------+------+\n",
      "|               en|520013|\n",
      "|               fr| 65443|\n",
      "|               es| 60359|\n",
      "|               de| 48525|\n",
      "|               ja| 45107|\n",
      "|               zh| 38067|\n",
      "|               pt| 33848|\n",
      "|               ru| 24613|\n",
      "|               it| 23886|\n",
      "|               ko| 13370|\n",
      "|               ar|  9820|\n",
      "|               nl|  9414|\n",
      "|               sv|  8954|\n",
      "|               cs|  8924|\n",
      "|               hi|  8678|\n",
      "|               tr|  8142|\n",
      "|               pl|  7568|\n",
      "|               tl|  7281|\n",
      "|               xx|  6697|\n",
      "|               da|  5664|\n",
      "+-----------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT original_language, COUNT(*) AS count\n",
    "    FROM movies\n",
    "    GROUP BY original_language\n",
    "    ORDER BY count DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "249788b0-fb1e-4ed4-b8db-8c705a332753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+---------+\n",
      "|rating_level|movie_count|avg_votes|\n",
      "+------------+-----------+---------+\n",
      "|        good|     143276|    132.2|\n",
      "|   excellent|      60170|    35.24|\n",
      "|     average|     127253|    29.17|\n",
      "|        poor|     717876|     0.24|\n",
      "+------------+-----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count how many movies are in each rating level\n",
    "# Also calculate the average vote count per category\n",
    "spark.sql(\"\"\"\n",
    "    SELECT rating_level,\n",
    "           COUNT(*) AS movie_count,\n",
    "           ROUND(AVG(vote_count), 2) AS avg_votes\n",
    "    FROM movies\n",
    "    GROUP BY rating_level\n",
    "    ORDER BY avg_votes DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94891cf4-533f-4539-b937-046e1cceb19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|avg_runtime|\n",
      "+-----------+\n",
      "|      45.65|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculating the average runtime of all movies\n",
    "spark.sql(\"\"\"\n",
    "    SELECT ROUND(AVG(runtime), 2) AS avg_runtime\n",
    "    FROM movies\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bda6406e-6bdb-4b4c-a7b9-75ca9619d1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing of required libraries for ML\n",
    "import pandas as pd  # for data handling\n",
    "from pyspark.sql.functions import col   # column operation\n",
    "from sklearn.model_selection import train_test_split   # data splitting\n",
    "from sklearn.ensemble import RandomForestClassifier   # model training\n",
    "from sklearn.metrics import classification_report, confusion_matrix   # model evauluation\n",
    "from sklearn.preprocessing import LabelEncoder   # label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "305b0978-6a42-4f05-9ed9-5c605a3e5bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Spark DataFrame to Pandas for scikit-learn\n",
    "pandas_df = df_cleaned.select(\"runtime\", \"vote_count\", \"original_language\", \"rating_level\").toPandas()\n",
    "\n",
    "# Encode the target column\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_rating = LabelEncoder()\n",
    "pandas_df[\"rating_encoded\"] = le_rating.fit_transform(pandas_df[\"rating_level\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26722048-66c7-44f6-b493-250f2a9a49e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode the target variable (rating_level) to numeric values\n",
    "le_rating = LabelEncoder()\n",
    "pandas_df[\"rating_encoded\"] = le_rating.fit_transform(pandas_df[\"rating_level\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "021862c7-cab4-4280-8f4c-513cd45077c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['runtime', 'vote_count', 'original_language', 'rating_level',\n",
      "       'rating_encoded'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(pandas_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99c180de-2fc2-4447-90d7-859ee81ce07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting runtime and vote_count to numeric in case of strings\n",
    "pandas_df[\"runtime\"] = pd.to_numeric(pandas_df[\"runtime\"], errors=\"coerce\")\n",
    "pandas_df[\"vote_count\"] = pd.to_numeric(pandas_df[\"vote_count\"], errors=\"coerce\")\n",
    "\n",
    "# Fill any missing values with 0\n",
    "pandas_df.fillna(0, inplace=True)\n",
    "\n",
    "# Convert runtime and vote_count to numeric in case they are strings\n",
    "pandas_df[\"runtime\"] = pd.to_numeric(pandas_df[\"runtime\"], errors=\"coerce\")\n",
    "pandas_df[\"vote_count\"] = pd.to_numeric(pandas_df[\"vote_count\"], errors=\"coerce\")\n",
    "\n",
    "# Filling any missing values with 0\n",
    "pandas_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "247670b7-98f4-4dc5-aed0-f927377e9296",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# Create language_encoded from original_language\n",
    "indexer = StringIndexer(inputCol=\"original_language\", outputCol=\"language_encoded\")\n",
    "df_encoded = indexer.fit(df_cleaned).transform(df_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7cee20b9-defd-4428-b201-d369c86c1d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer  # Encoding tool\n",
    "\n",
    "# Handling null values safely during encoding\n",
    "indexer = StringIndexer(\n",
    "    inputCol=\"original_language\",   # column to encode\n",
    "    outputCol=\"language_encoded\",   # new numeric column\n",
    "    handleInvalid=\"keep\"    # keeping nulls as seperate category\n",
    ")\n",
    "# Apply encoding transformation\n",
    "df_encoded = indexer.fit(df_cleaned).transform(df_cleaned) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf291d2f-c3da-4c83-a0df-81aa18fb92d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df = df_encoded.select(\"runtime\", \"vote_count\", \"language_encoded\", \"rating_level\").toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a813de5-5f7b-48b8-93d7-e9feeb1a261e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'rating_encoded'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'rating_encoded'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m X \u001b[38;5;241m=\u001b[39m pandas_df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mruntime\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvote_count\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage_encoded\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Defining the target variable, dependent variable\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mpandas_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrating_encoded\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Spliting the dataset: 80% training, 20% testing\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'rating_encoded'"
     ]
    }
   ],
   "source": [
    "# Defining the features, independent variables\n",
    "X = pandas_df[[\"runtime\", \"vote_count\", \"language_encoded\"]]\n",
    "\n",
    "# Defining the target variable, dependent variable\n",
    "y = pandas_df[\"rating_encoded\"]\n",
    "\n",
    "# Spliting the dataset: 80% training, 20% testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f22edf-d36b-4665-9e6c-ab100b4c2fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Convert the 'rating_level' column to numeric labels\n",
    "le_rating = LabelEncoder()\n",
    "pandas_df[\"rating_encoded\"] = le_rating.fit_transform(pandas_df[\"rating_level\"])\n",
    "\n",
    "# Check result\n",
    "pandas_df[[\"rating_level\", \"rating_encoded\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93f15e2-b305-4a30-854e-816a21047a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.dtypes)\n",
    "print(X_train.isnull().sum())\n",
    "print(y_train.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b555fe5d-cc15-4164-9bde-c35331965d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numeric values (object â†’ float)\n",
    "X_train[\"runtime\"] = pd.to_numeric(X_train[\"runtime\"], errors=\"coerce\")\n",
    "X_train[\"vote_count\"] = pd.to_numeric(X_train[\"vote_count\"], errors=\"coerce\")\n",
    "X_test[\"runtime\"] = pd.to_numeric(X_test[\"runtime\"], errors=\"coerce\")\n",
    "X_test[\"vote_count\"] = pd.to_numeric(X_test[\"vote_count\"], errors=\"coerce\")\n",
    "\n",
    "# Fill missing values with 0\n",
    "X_train.fillna(0, inplace=True)\n",
    "X_test.fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdd6ff8-08b9-4cf9-ba0e-91b0d1092f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c1d8f6-d1bd-4325-a844-0b9b48bb9f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the results using the test set\n",
    "y_pred = rf_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fbbcf0-2572-46e6-8e73-e60e393dfbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905b82c5-7a49-4800-b082-d33ad7b4fbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00363c31-7f64-47b7-9844-6c6d963cbe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy calculating\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca74083-02b8-4575-8b07-f92ba34ab176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Generating the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plotting the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=le_rating.classes_, yticklabels=le_rating.classes_)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c155ecc1-6efd-4a6f-902c-84cef2d69db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting of feature importance from random forest and importance score\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=importances, y=feature_names, hue=feature_names, dodge=False, palette=\"Set2\", legend=False)\n",
    "plt.title(\"Feature Importance from Random Forest\")\n",
    "plt.xlabel(\"Importance Score\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b7cba9-70d3-42b6-87c1-bfe565131e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print model accuracy to see how well it works\n",
    "print(\"Model Accuracy:\", round(accuracy_score(y_test, y_pred), 4))\n",
    "\n",
    "# Print classification report to understand precision, recall, and f1-score\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=le_rating.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3db842-bc70-4265-a917-5f10f3c2a61d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "7b90cbab-4f4c-4b83-9eae-f8794f3a836c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
